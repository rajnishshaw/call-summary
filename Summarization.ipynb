{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9618ca23-22a4-4117-aded-9e97d4493f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name: asr/, size: 0\n",
      "<class 'pandas.errors.EmptyDataError'>\n",
      "Empty file: asr/\n",
      "file_name: asr/auo-call-asr-script.csv, size: 1337\n",
      "1\n",
      "file_name: asr/health-call-asr-script.csv, size: 1842\n",
      "2\n",
      "---\n",
      "Uploading result\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "# create bedrock object\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "s3_client = boto3.client(\"s3\")\n",
    "# S3 bucket\n",
    "bucket_name = \"callsummarystack-assetbucket-nr5kcqsneged\"\n",
    "#configurations\n",
    "temp_config=0\n",
    "top_p_config=0.995\n",
    "top_k_config=250\n",
    "max_token_config=1000\n",
    "# Prompt for LLM\n",
    "SUMMARY_INSTRUCTIONS='''Summarize the conversation between a caller and agent  in 3-5 sentences. \n",
    "    Focus ONLY on : What is the caller's goal/issue, How was it resolved , is any follow up action to be taken.\n",
    "    If the conversation is not long enough to Summarize then just return 'NOT Applicable'.\n",
    "    Here is a conversation between a call center agent and  caller : '''\n",
    "\n",
    "# Summarizes the ASR script by invoking the Titan model\n",
    "def summarize_titan(asr_script):\n",
    "    query_input = \"\\n\\n\".join([SUMMARY_INSTRUCTIONS, asr_script])\n",
    "    query_context = {\n",
    "       \"inputText\": query_input,\n",
    "       \"textGenerationConfig\": {\n",
    "           \"maxTokenCount\": max_token_config,\n",
    "           \"stopSequences\": [\"User:\"],\n",
    "           \"temperature\":temp_config,\n",
    "           \"topP\":1\n",
    "        }\n",
    "    }\n",
    "    #print(\"---------asr_script \")\n",
    "    #print(asr_script)\n",
    "    #print(\"---------\")\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId = 'amazon.titan-text-express-v1',\n",
    "        contentType = \"application/json\",\n",
    "        accept = \"*/*\",\n",
    "        body = json.dumps(query_context)\n",
    "        )\n",
    "    model_response = json.loads(response['body'].read().decode('utf-8'))\n",
    "    summary=json.dumps(model_response['results'][0]['outputText'])\n",
    "    #print(\"---------Titan \")\n",
    "    #print(summary)\n",
    "    #print(\"---------\")\n",
    "    return summary\n",
    "\n",
    "# Summarizes the ASR script by invoking the Claude model\n",
    "def summarize_claude(asr_script):\n",
    "    # Create the payload to provide to the Anthropic model.\n",
    "    body_claude = {\n",
    "        \"prompt\": f\"\\n\\nHuman: {SUMMARY_INSTRUCTIONS}{asr_script}\\n\\nAssistant:\",\n",
    "        \"temperature\": temp_config,\n",
    "        \"top_p\": top_p_config,\n",
    "        \"top_k\": top_k_config,\n",
    "        \"max_tokens_to_sample\": max_token_config,\n",
    "        \"stop_sequences\": [\"\\\\n\\\\nHuman:\"]\n",
    "    }\n",
    "\n",
    "    # Invoke the Anthropic model using the payload.\n",
    "    response_claude = bedrock.invoke_model(\n",
    "           modelId=\"anthropic.claude-v2:1\", #\"anthropic.claude-v2\"\n",
    "           contentType=\"application/json\",\n",
    "           accept=\"*/*\",\n",
    "           body=json.dumps(body_claude)\n",
    "    )\n",
    "    assistant_response = json.loads(response_claude['body'].read())['completion']\n",
    "    #print(\"---------claude \")\n",
    "    #print(assistant_response)\n",
    "    #print(\"---------\")\n",
    "    return assistant_response\n",
    "    \n",
    "# Summarizes the ASR script by invoking the Jurassic-2 Ultra model\n",
    "def summarize_j2ultra(asr_script):\n",
    "    # Create the payload to provide to the Anthropic model.\n",
    "    query_input = \"\\n\\n\".join([SUMMARY_INSTRUCTIONS, asr_script])\n",
    "    body_ai = {\n",
    "        \"prompt\": query_input,\n",
    "        \"maxTokens\": max_token_config,\n",
    "        \"temperature\": top_p_config,\n",
    "        \"topP\": top_p_config\n",
    "    }\n",
    "\n",
    "    # Invoke the Anthropic model using the payload.\n",
    "    response_ai = bedrock.invoke_model(\n",
    "        modelId=\"ai21.j2-ultra-v1\", \n",
    "        contentType=\"application/json\",\n",
    "        accept=\"*/*\",\n",
    "        body=json.dumps(body_ai)\n",
    "    )\n",
    "    response_body = json.loads(response_ai.get('body').read())\n",
    "    summary=response_body.get('completions')[0].get('data').get('text')\n",
    "    #print(\"---------AI21 Labs \")\n",
    "    #print(summary)\n",
    "    #print(\"---------\")\n",
    "    return summary\n",
    "\n",
    "\n",
    "# Processes ASR (Automatic Speech Recognition) scripts and summarize results\n",
    "def process_audio_asr():    \n",
    "    # Create a DataFrame \n",
    "    df = pd.DataFrame({'col1': ['File Name'], 'col2': ['ASR Script'], 'col3': ['Titan'], 'col4': ['claude'], 'col5': ['Ai21']})\n",
    "    \n",
    "    cnt=0\n",
    "    # load the asr scripts\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=\"asr/\")\n",
    "    files = response.get(\"Contents\")\n",
    "    for file in files:\n",
    "        #loop for each script\n",
    "        key = file['Key']\n",
    "        print(f\"file_name: {file['Key']}, size: {file['Size']}\")\n",
    "        obj = s3_client.get_object(Bucket='callsummarystack-assetbucket-nr5kcqsneged', Key=key)\n",
    "        try:\n",
    "            data = pd.read_csv(obj['Body'])\n",
    "            # Convert DataFrame to string\n",
    "            data_string = \"\"\n",
    "            summTitan=\"\"\n",
    "            summClaude=\"\"\n",
    "            summAi21=\"\"\n",
    "            #prepare the string for entire conversation\n",
    "            for index, row in data.iterrows():\n",
    "                row_string = \"\"\n",
    "                for col in row:\n",
    "                    row_string += str(col) + \":\"\n",
    "                row_string += \"\\n\"\n",
    "                data_string += row_string\n",
    "            #print(data_string)\n",
    "            \n",
    "            #call Bedrock models \n",
    "            summTitan=summarize_titan(data_string)\n",
    "            # Add 15 second sleep\n",
    "            time.sleep(15)\n",
    "            summClaude=summarize_claude(data_string)\n",
    "            # Add 15 second sleep\n",
    "            time.sleep(15)\n",
    "            summAi21=summarize_j2ultra(data_string)\n",
    "            # Add 15 second sleep\n",
    "            time.sleep(15)\n",
    "            \n",
    "            new_row = pd.DataFrame({'col1': [key], 'col2': [data_string], 'col3': [summTitan], 'col4': [summClaude], 'col5': [summAi21]})\n",
    "            # concat to existing DataFrame\n",
    "            df = pd.concat([df, new_row]).reset_index(drop=True)\n",
    "            cnt=cnt+1\n",
    "            print(cnt)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(type(e))\n",
    "            print(f\"Empty file: {key}\")\n",
    "            continue\n",
    "\n",
    "    print(\"---\")\n",
    "    # Upload CSV to S3\n",
    "    #s3_w = boto3.client(\"s3\")\n",
    "    # Get datetime stamp \n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    # Append to filename\n",
    "    filename = f'data-{timestamp}.csv' \n",
    "    # Save DataFrame to CSV\n",
    "    df.to_csv(filename)\n",
    "    print(\"Uploading result\")\n",
    "    # Upload the CSV to S3 \n",
    "    try:\n",
    "        s3_client.upload_file(filename, 'callsummarystack-assetbucket-nr5kcqsneged', f'asr_results/{filename}')\n",
    "    except :\n",
    "        print(\"Error in writing result\") \n",
    "    print(\"---\")\n",
    "        \n",
    "            \n",
    "            \n",
    "\n",
    "process_audio_asr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f6dcf-d3ce-4b02-8762-687660c42518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
